{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bRCL58REe3B-",
    "outputId": "4668d6c4-d81f-4334-891e-560c733e2889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFiOruQdLxzM"
   },
   "outputs": [],
   "source": [
    "# Execute if necessary\n",
    "# %%capture\n",
    "# !pip install pandas\n",
    "# !pip install pytorchtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O0HQGm7dLxzP"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "import xml.etree.ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00EmWpKfprZR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYVI_IhM6MZo"
   },
   "source": [
    "### Plotting - Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsCGnvPl6R-g"
   },
   "outputs": [],
   "source": [
    "def plot_training_loss(minibatch_losses, num_epochs, averaging_iterations=100, custom_label=''):\n",
    "\n",
    "    iter_per_epoch = len(minibatch_losses) // num_epochs\n",
    "\n",
    "    plt.figure()\n",
    "    ax1 = plt.subplot(1, 1, 1)\n",
    "    ax1.plot(range(len(minibatch_losses)),\n",
    "             (minibatch_losses), label=f'Minibatch Loss{custom_label}')\n",
    "    ax1.set_xlabel('Iterations')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    if len(minibatch_losses) < 1000:\n",
    "        num_losses = len(minibatch_losses) // 2\n",
    "    else:\n",
    "        num_losses = 1000\n",
    "\n",
    "    ax1.set_ylim([\n",
    "        0, np.max(minibatch_losses[num_losses:])*1.5\n",
    "        ])\n",
    "\n",
    "    ax1.plot(np.convolve(minibatch_losses,\n",
    "                         np.ones(averaging_iterations,)/averaging_iterations,\n",
    "                         mode='valid'),\n",
    "             label=f'Running Average{custom_label}')\n",
    "    ax1.legend()\n",
    "\n",
    "    ###################\n",
    "    # Set scond x-axis\n",
    "    ax2 = ax1.twiny()\n",
    "    newlabel = list(range(num_epochs+1))\n",
    "\n",
    "    newpos = [e*iter_per_epoch for e in newlabel]\n",
    "\n",
    "    ax2.set_xticks(newpos[::10])\n",
    "    ax2.set_xticklabels(newlabel[::10])\n",
    "\n",
    "    ax2.xaxis.set_ticks_position('bottom')\n",
    "    ax2.xaxis.set_label_position('bottom')\n",
    "    ax2.spines['bottom'].set_position(('outward', 45))\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_xlim(ax1.get_xlim())\n",
    "    ###################\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "def plot_accuracy(train_acc, valid_acc):\n",
    "\n",
    "    num_epochs = len(train_acc)\n",
    "\n",
    "    plt.plot(np.arange(1, num_epochs+1), \n",
    "             train_acc, label='Training')\n",
    "    plt.plot(np.arange(1, num_epochs+1),\n",
    "             valid_acc, label='Validation')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "def plot_generated_images(data_loader, model, device, \n",
    "                          unnormalizer=None,\n",
    "                          figsize=(20, 2.5), n_images=15, modeltype='autoencoder'):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=n_images, \n",
    "                             sharex=True, sharey=True, figsize=figsize)\n",
    "    \n",
    "    for batch_idx, (features, _) in enumerate(data_loader):\n",
    "        \n",
    "        features = features.to(device)\n",
    "\n",
    "        color_channels = features.shape[1]\n",
    "        image_height = features.shape[2]\n",
    "        image_width = features.shape[3]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if modeltype == 'autoencoder':\n",
    "                decoded_images = model(features)[:n_images]\n",
    "            elif modeltype == 'VAE':\n",
    "                encoded, z_mean, z_log_var, decoded_images = model(features)[:n_images]\n",
    "            else:\n",
    "                raise ValueError('`modeltype` not supported')\n",
    "\n",
    "        orig_images = features[:n_images]\n",
    "        break\n",
    "\n",
    "    for i in range(n_images):\n",
    "        for ax, img in zip(axes, [orig_images, decoded_images]):\n",
    "            curr_img = img[i].detach().to(torch.device('cpu'))        \n",
    "            if unnormalizer is not None:\n",
    "                curr_img = unnormalizer(curr_img)\n",
    "\n",
    "            if color_channels > 1:\n",
    "                curr_img = np.transpose(curr_img, (1, 2, 0))\n",
    "                ax[i].imshow(curr_img)\n",
    "            else:\n",
    "                ax[i].imshow(curr_img.view((image_height, image_width)), cmap='binary')\n",
    "                \n",
    "                \n",
    "def plot_latent_space_with_labels(num_classes, data_loader, encoding_fn, device):\n",
    "    d = {i:[] for i in range(num_classes)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (features, targets) in enumerate(data_loader):\n",
    "\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            embedding = encoding_fn(features)\n",
    "\n",
    "            for i in range(num_classes):\n",
    "                if i in targets:\n",
    "                    mask = targets == i\n",
    "                    d[i].append(embedding[mask].to('cpu').numpy())\n",
    "\n",
    "    colors = list(mcolors.TABLEAU_COLORS.items())\n",
    "    for i in range(num_classes):\n",
    "        d[i] = np.concatenate(d[i])\n",
    "        plt.scatter(\n",
    "            d[i][:, 0], d[i][:, 1],\n",
    "            color=colors[i][1],\n",
    "            label=f'{i}',\n",
    "            alpha=0.5)\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "def plot_images_sampled_from_vae(model, device, latent_size, unnormalizer=None, num_images=10):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        ##########################\n",
    "        ### RANDOM SAMPLE\n",
    "        ##########################    \n",
    "\n",
    "        rand_features = torch.randn(num_images, latent_size).to(device)\n",
    "        new_images = model.decoder(rand_features)\n",
    "        color_channels = new_images.shape[1]\n",
    "        image_height = new_images.shape[2]\n",
    "        image_width = new_images.shape[3]\n",
    "\n",
    "        ##########################\n",
    "        ### VISUALIZATION\n",
    "        ##########################\n",
    "\n",
    "        image_width = 28\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=num_images, figsize=(10, 2.5), sharey=True)\n",
    "        decoded_images = new_images[:num_images]\n",
    "\n",
    "        for ax, img in zip(axes, decoded_images):\n",
    "            curr_img = img.detach().to(torch.device('cpu'))        \n",
    "            if unnormalizer is not None:\n",
    "                curr_img = unnormalizer(curr_img)\n",
    "\n",
    "            if color_channels > 1:\n",
    "                curr_img = np.transpose(curr_img, (1, 2, 0))\n",
    "                ax.imshow(curr_img)\n",
    "            else:\n",
    "                ax.imshow(curr_img.view((image_height, image_width)), cmap='binary') \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78n5tAZE6rZX"
   },
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tpKPpt_Y6utP"
   },
   "outputs": [],
   "source": [
    "def set_deterministic():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    torch.set_deterministic(True)\n",
    "    \n",
    "    \n",
    "def set_all_seeds(seed):\n",
    "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAblxcIKLZI0"
   },
   "source": [
    "### Evaluate - Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWHWDboYLdou"
   },
   "outputs": [],
   "source": [
    "def compute_epoch_loss_autoencoder(model, data_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    curr_loss, num_examples = 0., 0\n",
    "    with torch.no_grad():\n",
    "        for features, _ in data_loader:\n",
    "            features = features.to(device)\n",
    "            logits = model(features)\n",
    "            loss = loss_fn(logits, features, reduction='sum')\n",
    "            num_examples += features.size(0)\n",
    "            curr_loss += loss\n",
    "\n",
    "        curr_loss = curr_loss / num_examples\n",
    "        return curr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUrZvRTgQxDY"
   },
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLvlPD_QLxzQ"
   },
   "source": [
    "# Práctica 7: Redes Neuronales (Autoencoders Variacionales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgXbViXVLxzS"
   },
   "source": [
    "__Instrucciones__: A continuación hay una lista de funciones que debe implementar o tareas que debe desarrollar. La descripción de cada una de ellas se encuentra en la definición de cada una de las funciones.\n",
    "\n",
    "La entrega de la práctica será en la siguiente sesión a menos que la indicación sea otra. La revisión iniciará al iniciar la sesión y únicamente podrá ser evaluada durante la duración de la sesión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X35Mj2_ELxzT"
   },
   "source": [
    "__Para esta práctica se deben usar bibliotecas__. Se recomienda el uso de:\n",
    "\n",
    "- scikit-learn (https://scikit-learn.org/stable/)\n",
    "- plotly express (https://plotly.com/python/plotly-express/)\n",
    "- torch (https://pytorch.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZKq75JJLxzT"
   },
   "source": [
    "## Asignación 1\n",
    "\n",
    "Seleccione algun dataset de su preferencia para el cual sea viable entrenar un modelo generativo (VAE), preferentemente de imagenes (pequeñas). Particione sus datos para poder realizar selección de modelos (__conjunto de validación__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EeCWcPY-wPtH"
   },
   "outputs": [],
   "source": [
    "#with zipfile.ZipFile('/content/drive/MyDrive/ModeladoPredicitivo/all-dogs.zip','r') as zip_file:\n",
    "#  zip_file.extractall('/content/drive/MyDrive/ModeladoPredicitivo/all-dogs/dogs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OOdLsUw8xglJ",
    "outputId": "0dbd1f99-2b7b-4830-b951-d4530cfc4d78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20579\n"
     ]
    }
   ],
   "source": [
    "root = '/content/drive/MyDrive/ModeladoPredicitivo/all-dogs/dogs/all-dogs'\n",
    "img_list = os.listdir(root)\n",
    "print(len(img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmUwcE5lwVAM"
   },
   "outputs": [],
   "source": [
    "root = '/content/drive/MyDrive/ModeladoPredicitivo/all-dogs/dogs/'\n",
    "dataset = datasets.ImageFolder(root, transform=transforms.Compose([\n",
    "                          transforms.RandomResizedCrop(64, scale=(0.9, 1.0), ratio=(1., 1.)),\n",
    "                          transforms.RandomHorizontalFlip(),\n",
    "                          transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
    "                          transforms.ToTensor(),\n",
    "                      ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qrPd4jBXD7fv",
    "outputId": "37f22ad0-b147-41fd-a509-8c4affc1814b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: 16463 \n",
      "test_set: 4116\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(img_list) * 0.8)\n",
    "test_size = len(img_list) - train_size\n",
    "train_set, test_set = data.random_split(dataset, [train_size, test_size])\n",
    "print(f\"train set: {len(train_set)} \\ntest_set: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1FaTloF5L6DI",
    "outputId": "2a968d00-19f1-4f23-a86d-601812a891dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_set[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "tfjd_XUGzXmF",
    "outputId": "92bb9133-42fc-422e-d157-a7685c3f485f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7FCFD71591B0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensor = train_set[0][0]\n",
    "transform = transforms.ToPILImage()\n",
    "img = transform(tensor)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "Ga3_cjl0znfg",
    "outputId": "9c2c5fdf-2f9a-46f9-8d50-754db5c5f2f2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7FCFD7159030>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensor = test_set[0][0]\n",
    "transform = transforms.ToPILImage()\n",
    "img = transform(tensor)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "236I131OLxzU"
   },
   "source": [
    "## Asignación 2\n",
    "\n",
    "Realice un análisis exploratorio de datos y el preprocesamiento necesario para el dataset seleccionado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9YOdREkLxzU"
   },
   "source": [
    "## Asignación 3\n",
    "\n",
    "Ajuste un Autoencoder Variacional (VAE) que permita realizar la generación de nuevos datos. Debe generar las curvas de entrenamiento (y graficarlas) e implementar el método de early stopping para seleccionar el modelo más adecuado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0Q0AV497GGY",
    "outputId": "be52c1d6-1ee3-4dc8-fa3e-8594939effe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in : cuda\n"
     ]
    }
   ],
   "source": [
    "#Setings\n",
    "DEVICE = torch.device(f'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Running in : {DEVICE}\")\n",
    "\n",
    "#HyperParams\n",
    "RANDOM_SEED = 123\n",
    "LEARNING_RATE = 3e-4\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IThufp838uAY"
   },
   "outputs": [],
   "source": [
    "set_deterministic #Forces CUDA to use deterministic algorithms only\n",
    "set_all_seeds(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QL2zH9-aA_aQ"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_set,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              num_workers=0,\n",
    "                              shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=test_set,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              num_workers=0,\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S66M8tai-zbv",
    "outputId": "3f27f5e0-e725-4924-d8d8-97aebe680472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset\n",
    "print('Training Set:\\n')\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    #print(labels[:10])\n",
    "    break\n",
    "    \n",
    "# Checking the dataset\n",
    "print('\\nValidation Set:')\n",
    "for images, labels in valid_loader:  \n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    #print(labels[:10])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_em2Qg4nBzhI"
   },
   "outputs": [],
   "source": [
    "###MODEL\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)#The new dimension has to be compatible with the former\n",
    "\n",
    "\n",
    "class Trim(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :64, :64] #Trim the output layer to the size of the image\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(#Sequential container, modules wil be added to it in the order they are passed in \n",
    "                nn.Conv2d(3, 32, stride=2, kernel_size=3, bias=False, padding=1),\n",
    "                nn.BatchNorm2d(32), #Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift \n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "                nn.Dropout2d(0.25), #During training drop nodes and scale activations by (1-p)  p = drop probability\n",
    "                # (256,32,32,32)\n",
    "                nn.Conv2d(32, 64, stride=2, kernel_size=3, bias=False, padding=1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "                nn.Dropout2d(0.25),\n",
    "                # (256,64,16,16)\n",
    "                nn.Conv2d(64, 64, stride=2, kernel_size=3, bias=False, padding=1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "                nn.Dropout2d(0.25),\n",
    "                # (256,64,8,8)\n",
    "                nn.Conv2d(64, 64, stride=2, kernel_size=3, bias=False, padding=1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "                nn.Dropout2d(0.25),\n",
    "                # (256, 64, 4, 4)\n",
    "                nn.Flatten()#(256,1024)\n",
    "        )    \n",
    "        \n",
    "        self.z_mean = torch.nn.Linear(1024, 200)\n",
    "        self.z_log_var = torch.nn.Linear(1024, 200)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "                torch.nn.Linear(200, 1024),\n",
    "                Reshape(-1, 64, 4, 4),\n",
    "                # (256,64,4,4)\n",
    "                nn.ConvTranspose2d(64, 64, stride=2, kernel_size=3),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "                nn.Dropout2d(0.25),\n",
    "                #(256,64,9,9)\n",
    "                nn.ConvTranspose2d(64, 64, stride=2, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "                nn.Dropout2d(0.25),\n",
    "                #(256,64,19,19)\n",
    "                nn.ConvTranspose2d(64, 32, stride=2, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "                nn.Dropout2d(0.25),\n",
    "                #(256,32,37,37)\n",
    "                nn.ConvTranspose2d(32, 3, stride=2, kernel_size=3, padding=1),\n",
    "                #(256,3,73,73)\n",
    "                Trim(),  # (256, 3, 64, 64)\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "\n",
    "\n",
    "    def encoding_fn(self, x):\n",
    "        x = self.encoder(x)\n",
    "        z_mean, z_log_var = self.z_mean(x), self.z_log_var(x)\n",
    "        encoded = self.reparameterize(z_mean, z_log_var)\n",
    "        return encoded\n",
    "\n",
    "    #Help us make the monte carlo estimate of the marginal likelihood differentiable by writing z in terms of epsilon   \n",
    "    def reparameterize(self, z_mu, z_log_var):\n",
    "        eps = torch.randn(z_mu.size(0), z_mu.size(1)).to(z_mu.get_device())\n",
    "        z = z_mu + eps * torch.exp(z_log_var/2.) \n",
    "        return z\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        print(x.shape)\n",
    "        z_mean, z_log_var = self.z_mean(x), self.z_log_var(x)\n",
    "        print(z_mean, z_log_var)\n",
    "        encoded = self.reparameterize(z_mean, z_log_var)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, z_mean, z_log_var, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d2fa3fx_IHxF"
   },
   "outputs": [],
   "source": [
    "set_all_seeds(RANDOM_SEED)\n",
    "\n",
    "model = VAE()\n",
    "model.to(DEVICE)\n",
    "\n",
    "#instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clt4BWfAJda7"
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "def train_vae_v1(num_epochs, model, optimizer, device, \n",
    "                 train_loader, valid_loader, loss_fn=None,\n",
    "                 logging_interval=100, \n",
    "                 skip_epoch_stats=False,\n",
    "                 reconstruction_term_weight=1,\n",
    "                 save_model=None):\n",
    "    \n",
    "    log_dict = {'train_combined_loss_per_batch': [],\n",
    "                'train_combined_loss_per_epoch': [],\n",
    "                'test_combined_loss_per_epoch': [],\n",
    "                'train_reconstruction_loss_per_batch': [],\n",
    "                'train_kl_loss_per_batch': []}\n",
    "\n",
    "\n",
    "\n",
    "    if loss_fn is None:\n",
    "        loss_fn = F.mse_loss\n",
    "\n",
    "    start_time = time.time()\n",
    "    early_stopper = EarlyStopper(patience=3, min_delta=10)\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        model.train()\n",
    "        for batch_idx, (features, _) in enumerate(train_loader):\n",
    "            print(features.shape)\n",
    "            features = features.to(device)\n",
    "\n",
    "            # FORWARD AND BACK PROP\n",
    "            encoded, z_mean, z_log_var, decoded = model.forward(features)\n",
    "            \n",
    "            # total loss = reconstruction loss + KL divergence\n",
    "            kl_div = -0.5 * torch.sum(1 + z_log_var \n",
    "                                      - z_mean**2 \n",
    "                                      - torch.exp(z_log_var), \n",
    "                                      axis=1) # sum over latent dimension\n",
    "\n",
    "            batchsize = kl_div.size(0)\n",
    "            kl_div = kl_div.mean() # average over batch dimension\n",
    "    \n",
    "            pixelwise = loss_fn(decoded, features, reduction='none')\n",
    "            pixelwise = pixelwise.view(batchsize, -1).sum(axis=1) # sum over pixels\n",
    "            pixelwise = pixelwise.mean() # average over batch dimension\n",
    "            \n",
    "            loss = reconstruction_term_weight*pixelwise + kl_div\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # UPDATE MODEL PARAMETERS\n",
    "            optimizer.step()\n",
    "\n",
    "            # LOGGING\n",
    "            log_dict['train_combined_loss_per_batch'].append(loss.item())\n",
    "            log_dict['train_reconstruction_loss_per_batch'].append(pixelwise.item())\n",
    "            log_dict['train_kl_loss_per_batch'].append(kl_div.item())\n",
    "            \n",
    "            if not batch_idx % logging_interval:\n",
    "                print('Epoch: %03d/%03d | Batch %04d/%04d | Loss: %.4f'\n",
    "                      % (epoch+1, num_epochs, batch_idx,\n",
    "                          len(train_loader), loss))\n",
    "\n",
    "        if not skip_epoch_stats:\n",
    "            model.eval()\n",
    "            \n",
    "            with torch.set_grad_enabled(False):  # save memory during inference\n",
    "                \n",
    "                train_loss = compute_epoch_loss_autoencoder(\n",
    "                    model, train_loader, loss_fn, device)\n",
    "                print('***Epoch: %03d/%03d | Loss: %.3f' % (\n",
    "                      epoch+1, num_epochs, train_loss))\n",
    "                log_dict['train_combined_per_epoch'].append(train_loss.item())\n",
    "\n",
    "                #validation\n",
    "                validation_loss = compute_epoch_loss_autoencoder(\n",
    "                    model, valid_loader, loss_fn, device)\n",
    "                print('***Epoch: %03d/%03d | Loss: %.3f' % (\n",
    "                      epoch+1, num_epochs, validation_loss))\n",
    "                log_dict['test_combined_per_epoch'].append(validation_loss.item())\n",
    "\n",
    "        print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "\n",
    "        if early_stopper.early_stop(validation_loss):             \n",
    "          break\n",
    "    \n",
    "    print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))\n",
    "    if save_model is not None:\n",
    "        torch.save(model.state_dict(), save_model)\n",
    "\n",
    "    return log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umLC9ITrIRlE"
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "log_dict = train_vae_v1(num_epochs=EPOCHS, model=model, \n",
    "                        optimizer=optimizer, device=DEVICE, \n",
    "                        train_loader=train_loader,\n",
    "                        valid_loader = valid_loader,\n",
    "                        skip_epoch_stats=True,\n",
    "                        logging_interval=50,\n",
    "                        save_model='/content/drive/MyDrive/ModeladoPredicitivo/vae_doggos.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRIKxaR6UnQi"
   },
   "outputs": [],
   "source": [
    "plot_training_loss(log_dict['train_reconstruction_loss_per_batch'], NUM_EPOCHS, custom_label=\" (reconstruction)\")\n",
    "plot_training_loss(log_dict['train_kl_loss_per_batch'], NUM_EPOCHS, custom_label=\" (KL)\")\n",
    "plot_training_loss(log_dict['train_combined_loss_per_batch'], NUM_EPOCHS, custom_label=\" (combined)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGxPEngwLxzV"
   },
   "source": [
    "## Asignación 4\n",
    "\n",
    "Realice la generación de nuevos datos utilizando su modelo. Debe generar evidencia sobre el correcto funcionamiento de su modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5DiHgBlS1jx"
   },
   "outputs": [],
   "source": [
    "#train set\n",
    "plot_generated_images(data_loader=train_loader,\n",
    "                      model=model,\n",
    "                      #unnormalizer=unnormalizer,\n",
    "                      device=DEVICE,\n",
    "                      modeltype='VAE')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aVHWbaSx5qBR"
   },
   "outputs": [],
   "source": [
    "#test set\n",
    "plot_generated_images(data_loader=test_loader,\n",
    "                      model=model,\n",
    "                      #unnormalizer=unnormalizer,\n",
    "                      device=DEVICE,\n",
    "                      modeltype='VAE')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wAmfjxMh5t18"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plot_images_sampled_from_vae(model=model, device=DEVICE, latent_size=200)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "GYVI_IhM6MZo",
    "78n5tAZE6rZX",
    "QAblxcIKLZI0"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
